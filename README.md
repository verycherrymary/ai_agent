**Проект по NLP - создание ИИ агента для поиска информации в интернете**

Исполнитель - Сучкова Мария

- основной ноутбук Suchkova_project_ai_agent.ipynb с исследованиями находится по ссылке (https://drive.google.com/file/d/1fdRNyNAFSJFCcIrg5MYAskc_ErLustKf/view?usp=sharing), эксперименты проводились на сайте Kaggle (предоставляется 30 часов в неделю для GPU,оперативная память 14гб) 
- файлы answer_agent_qwen1.csv, answer_agent_smol.csv, df_with_relevance_qwen3.csv - это сохраненные файлы с ответами агента (разных моделей) на вопросы из тренировочной выборки (110 вопросов)
- файл df_with_relevance_qwen3_test.csv - это сохраненный файл с ответами агента (Qwen3-8B) на вопросы из тестовой выборки (100 вопросов)

Задача:

- Необходимо создать LLM-агента, который будет оценивать релевантность организаций на Яндекс.Картах широким запросам (например, "ресторан с верандой" или "романтичный джаз-бар"). Такие запросы называются рубричными: пользователь здесь ищет не конкретную организацию, а идёт в Яндекс.Карты для поиска и выбора мест.
- LLM-агент должен будет самостоятельно находить необходимые данные для принятия правильного решения.

Данные: таблица со столбцами (которые использовались в работе, потому что они без пропусков)

- Text - запрос пользователя, 
- name - название организации в Яндекс картах, 
- address - адрес организации в Яндекс картах, 
- permalink - ссылка id на организацию в Яндекс картах, 
- normalized_main_rubric_name_ru - нормализованное название на русском языке, 
- relevance_new - оценка релевантности запросу (0- нерелевантно, 1 - релевантно, 0.1 - сомнительно)

План работы:

1. Построить бейзлайн:
- в качестве бейзлайна - использовалась логистическая регрессия со значением Eval test Accuracy: 0.63, test Accuracy: 0.70
- а также Catboost - Eval test Accuracy: 0.626, test Accuracy: 0.73
2. Разобраться с фреймворком для реализации LLM-агентов (предлагается использовать LangGraph, оба примера в доп. материалах используют его).
- я использовала в итоге библиотеку LangChain (AgentOutputParser, AgentAction, AgentFinish, AgentExecutor, initialize_agent)
3. Тестировала несколько LLM моделей в качестве агента - Qwen-2.5-3B, SmolLM3-3B, Qwen-3-8B - хотела попробовать реализовать бесплатного агента без обращения к API OpenAI
4. В качестве инструмента поиска в интернете пробовала TavilySearch и DuckDuckGoSearch
5. Реализовала сначала первую версию агента: предложила ему не принимать решение мгновенно, а ходить в поисковик для уточнения своего ответа.
6. Потом накладывала суммаризацию на ответ агента после поиска в интернете с окончательным выводом ответа Да или Нет, и сохранением в таблицу для дальнейшего подсчета точности
7. Промпты формировались по строчно по шаблону - 

prompt = (f"Есть ли {str(row.get('Text', '')).lower()} в организации ({row.get('normalized_main_rubric_name_ru', '')}) " 
                 f"с таким названием ({row.get('name', '')}) по адресу: {row.get('address', '')} ? ")

Пример промпта: "Есть ли еда1 в организации (Быстрое питание) с таким названием (Шаурма; Russky Gril; Русский Гриль) по адресу: Свердловская область, Нижний Тагил, улица Ильича, 23А ? 

Пример ответа агента: "Нет, заведения быстрого питания с названием «Русский Гриль» или подобным по указанному адресу в Нижнем Тагиле, Свердловская область, не найдено в доступной базе данных или интернет-источниках. Возможно, информация была предоставлена ошибочно. рекомендуется обратиться к местным источникам для получения дополнительной помощи."

Пример summary: "Нет" - summary кодировалось Да - 1, Нет -0, считалось accuracy по сравнению с значениями relevance_new

8. Второй подход - я использовала классификацию моделью rubert-tiny2 поверх ответа агента для того, чтобы получить 0 - нерелевантно, 1 - релевантно


**Выводы:**

- полученная точность на тестовом eval-dataset (100 строк) агента с моделью Qwen-3-8B составила 0.32 - это очень маленькая точность, возможно при тестировании на 500 строк, точность была бы и больше
- возможно стоит поменять способ постобработки ответов агента на что-то более точное (регулярные выражения),  а не классификация rubert-tiny2 и суммаризация Qwen-2.5-3B
- модель бейзлайна дают большую точность 0.63 на eval-dataset (большая точность скорее всего связана с объемом датасета 500 строк,  а не 100 строк как у агента)
- для агента стоит все таки пробовать более умную модель с большим количеством параметров, такие как GPT-4 или DeepSeekR1, но за это придется платить (количество токенов) или искать, где можно локально использовать такие большие модели

